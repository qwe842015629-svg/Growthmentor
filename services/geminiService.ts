import { GoogleGenerativeAI } from "@google/generative-ai";
import { ModelType, Message, Language } from "../types";
import { SYSTEM_INSTRUCTION, MODEL_CONFIGS } from "../constants";

export async function generateGeminiResponse(
  history: Message[],
  modelType: ModelType,
  language: Language,
  knowledgeBase?: string
) {
  const apiKey = import.meta.env.VITE_GEMINI_API_KEY;

  if (!apiKey) {
    console.error("âŒ è‡´å‘½é”™è¯¯: æœªæ‰¾åˆ° API Key");
    return { 
      text: "ç³»ç»Ÿé”™è¯¯ï¼šæœªæ£€æµ‹åˆ° API Keyã€‚è¯·è”ç³»ç®¡ç†å‘˜åœ¨ Vercel åå°é…ç½® VITE_GEMINI_API_KEYã€‚",
      groundingMetadata: null
    };
  }

  try {
    const genAI = new GoogleGenerativeAI(apiKey);
    
    // ã€å…³é”®ä¿®å¤ã€‘ä¼˜å…ˆä½¿ç”¨é…ç½®æ–‡ä»¶é‡Œçš„ gemini-2.5ï¼Œå¦‚æœè¯»å–å¤±è´¥ï¼Œå¼ºåˆ¶å…œåº•åˆ° gemini-2.5-flash
    const configName = MODEL_CONFIGS[modelType]?.modelName || 'gemini-2.5-flash';
    
    // åŒé‡ä¿é™©ï¼šå¦‚æœæ··å…¥äº†æ—§ç‰ˆæœ¬åå­—ï¼Œå¼ºåˆ¶çº æ­£ä¸º 2.5
    const safeModelName = (configName.includes('1.5') || configName.includes('preview'))
      ? 'gemini-2.5-flash' 
      : configName;

    console.log("ğŸš€ ä½¿ç”¨æ¨¡å‹:", safeModelName); 

    const model = genAI.getGenerativeModel({ model: safeModelName });

    // 1. è½¬æ¢å†å²è®°å½•æ ¼å¼
    let chatHistory = history.slice(0, -1).map(msg => ({
      role: msg.role === 'user' ? 'user' : 'model',
      parts: [{ text: msg.content }]
    }));

    // 2. å‰”é™¤ç¬¬ä¸€æ¡æ¬¢è¿è¯­ï¼ˆå¦‚æœæ˜¯ Model å‘è¨€ï¼‰
    if (chatHistory.length > 0 && chatHistory[0].role === 'model') {
      chatHistory.shift();
    }

    const chat = model.startChat({
      history: chatHistory,
      systemInstruction: SYSTEM_INSTRUCTION ? { role: 'system', parts: [{ text: SYSTEM_INSTRUCTION[language] }] } : undefined,
    });

    const lastMsgContent = history[history.length - 1].content;
    const finalPrompt = knowledgeBase 
      ? `ã€çŸ¥è¯†åº“å‚è€ƒä¿¡æ¯ã€‘:\n${knowledgeBase}\n\nã€ç”¨æˆ·é—®é¢˜ã€‘:\n${lastMsgContent}` 
      : lastMsgContent;

    const result = await chat.sendMessage(finalPrompt);
    const response = await result.response;
    
    return {
      text: response.text(),
      groundingMetadata: null 
    };

  } catch (error: any) {
    console.error("AI è¯·æ±‚å¤±è´¥:", error);
    return {
      text: `è¯·æ±‚å‡ºé”™: ${error.message || "æœªçŸ¥ç½‘ç»œé”™è¯¯"}ã€‚\n\n(æç¤ºï¼š1.5æ¨¡å‹å·²é€€å½¹ï¼Œè¯·ç¡®ä¿ä½¿ç”¨äº† gemini-2.5-flash)`,
      groundingMetadata: null
    };
  }
}

export async function extractInformationFromImage(base64Data: string, mimeType: string): Promise<string> {
  const apiKey = import.meta.env.VITE_GEMINI_API_KEY;
  if (!apiKey) {
      throw new Error("API Key missing");
  }

  const genAI = new GoogleGenerativeAI(apiKey);
  
  // ã€å…³é”®ä¿®å¤ã€‘å›¾ç‰‡è§£æä¹Ÿå¼ºåˆ¶ä½¿ç”¨ gemini-2.5-flash
  const model = genAI.getGenerativeModel({ model: 'gemini-2.5-flash' });

  try {
    const result = await model.generateContent([
      "Please transcribe all text visible in this image. If there are tables or structured data, maintain the structure.",
      {
        inlineData: {
          data: base64Data,
          mimeType: mimeType
        }
      }
    ]);
    return result.response.text();
  } catch (error) {
    console.error("Image extraction failed:", error);
    return "Error parsing image: " + (error as any).message;
  }
}
